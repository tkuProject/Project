{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d088d322",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from bs4 import BeautifulSoup,NavigableString, Tag\n",
    "import time\n",
    "import requests\n",
    "import re\n",
    "import csv\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "headers = {'content-type': 'text/html; charset=UTF-8','user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36(KHTML, like Gecko) Chrome/76.0.3809.132 Safari/537.36'\n",
    "}\n",
    "#s = Service(r\"/usr/local/bin/chromedriver\") #使用chromedriver、selenium\n",
    "driver = webdriver.Chrome()\n",
    "    \n",
    "driver.get(\"https://www.cardu.com.tw/\") #自動打開網頁（不要關）\n",
    "    \n",
    "time.sleep(5) #暫停\n",
    "    \n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser') #把script變成美麗湯可讀\n",
    "#print(soup.prettify())  #輸出排版後的HTML內容\n",
    "\n",
    "#爬卡排行的名稱\n",
    "card_ranking_type = [] \n",
    "results1 = soup.find_all('div', class_='text-center')\n",
    "for results in results1:\n",
    "    result = results.find('a').get('title')\n",
    "    card_ranking_type.append(result)\n",
    "    #print(result) #測試抓到的卡排行\n",
    "    \n",
    "card_ranking_type.pop(0) #頭兩個不需要 因此刪除\n",
    "card_ranking_type.pop(0)\n",
    "#for i in range(len(card_ranking_type)):\n",
    "    #print(card_ranking_type[i])\n",
    "\n",
    "#爬卡排行的網址\n",
    "card_ranking_link = []\n",
    "results1 = soup.find_all('div', class_='text-center')\n",
    "for results in results1:\n",
    "    result = results.find('a').get('href')\n",
    "    result = 'https://www.cardu.com.tw/'+result\n",
    "    card_ranking_link.append(result)\n",
    "    #print(result)\n",
    "\n",
    "card_ranking_link.pop(0) #頭兩個不需要 因此刪除\n",
    "card_ranking_link.pop(0)\n",
    "#for i in range(len(card_ranking_link)):\n",
    "    #print(card_ranking_link[i])\n",
    "\n",
    "ranking_dict = {\n",
    "    '排行名稱':card_ranking_type,\n",
    "    '排行連結':card_ranking_link,\n",
    "}\n",
    "df = pd.DataFrame(ranking_dict)\n",
    "folder_name = 'carducsv'\n",
    "path = \"/Users/takoyaki/Downloads/專題爬蟲\" \n",
    "folder_path = os.path.join(path, folder_name)\n",
    "if not os.path.isdir(folder_path):\n",
    "    os.makedirs(folder_path, mode=0o777)\n",
    "path0 = str(path+'/'+folder_name+\"/\")\n",
    "#path='/Users/takoyaki/Downloads/專題爬蟲/carducsv/'\n",
    "df.to_csv(path0+'icardu排行.csv', index = False)\n",
    "\n",
    "\n",
    "for k in range(len(card_ranking_link)):\n",
    "    \n",
    "    card_name1 = [] #卡名無門檻\n",
    "    card_name2 = [] #卡名有門檻\n",
    "    card_name = [] #卡名一般排行\n",
    "    card_link1 = [] #卡連結無門檻\n",
    "    card_link2 = [] #卡連結有門檻\n",
    "    card_link = [] #卡連結一般排行\n",
    "    #一般\n",
    "    block_name = []\n",
    "    block_one = [] #國內回饋\n",
    "    block_two = [] #國外回饋\n",
    "    block_three = [] #其他卡片\n",
    "    #無回饋\n",
    "    block_one1 = [] #國內回饋\n",
    "    block_two1 = [] #國外回饋\n",
    "    block_three1 = [] #其他卡片\n",
    "    #有回饋\n",
    "    block_one2 = [] #國內回饋\n",
    "    block_two2 = [] #國外回饋\n",
    "    block_three2 = [] #其他卡片\n",
    "    \n",
    "    print('☆'+card_ranking_type[k])\n",
    "    driver.get(card_ranking_link[k]) #自動打開網頁（不要關）\n",
    "    time.sleep(3) #暫停   \n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser') #把script變成美麗湯可讀\n",
    "    \n",
    "    results = soup.find_all('div', class_='col-md text-center col-4')\n",
    "    for result in results:\n",
    "        print(result.text)\n",
    "        block_name.append(result.text)\n",
    "    \n",
    "    if card_ranking_type[k] == '現金回饋':\n",
    "        \n",
    "        button= driver.find_element(By.ID, \"goodSet-tab\") #打開有門檻\n",
    "        button.click()\n",
    "        time.sleep(2)\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser') #把script變成美麗湯可讀\n",
    "        \n",
    "        i=0\n",
    "        results = soup.find_all('div', class_='col-md-11 wx-100-ph')\n",
    "        for result in results:\n",
    "            name = result.find('h5', class_='money_main mb-0') #卡名\n",
    "            link = result.find('a').get('href') #卡連結\n",
    "            \n",
    "            if i<10: #無門檻\n",
    "                card_name1.append(name.text)\n",
    "                card_link1.append('https://www.cardu.com.tw'+link[2:])\n",
    "            elif i==10: #有門檻換行\n",
    "                print('\\n')\n",
    "                card_name2.append(name.text)\n",
    "                card_link2.append('https://www.cardu.com.tw'+link[2:])\n",
    "            elif i>10: #有門檻\n",
    "                card_name2.append(name.text)\n",
    "                card_link2.append('https://www.cardu.com.tw'+link[2:])\n",
    "            print(name.text)\n",
    "            print('https://www.cardu.com.tw'+link[2:])\n",
    "            i+=1\n",
    "        results=soup.find_all('div', class_='row w-h-100') #幾張卡\n",
    "        \n",
    "        j=0\n",
    "        for result in results:\n",
    "            if j < 10: #無門檻\n",
    "                print(j)\n",
    "                i = 0\n",
    "                result1 = result.find_all('div', class_='col-md hv-center phone_block col-4 py-2 pc_rank_txt') #國內回饋+其他卡片\n",
    "                for re in result1:\n",
    "                    if i == 0:\n",
    "                        print(block_name[0] +':'+ re.find('p').text)\n",
    "                        block_one1.append(re.find('p').text) #國內回饋\n",
    "                    else:\n",
    "                        print(block_name[2] +':'+ re.find('p').text)\n",
    "                        block_three1.append(re.find('p').text) #其他卡片\n",
    "                    i+=1\n",
    "                    \n",
    "                result2 = result.find('div',class_='col-md hv-center border-left border-right phone_block col-4 py-2 pc_rank_txt') #國外回饋\n",
    "                print(block_name[1] +':'+ result2.find('p').text)\n",
    "                block_two1.append(result2.find('p').text)\n",
    "                \n",
    "            elif j == 10: #換行\n",
    "                print(j)\n",
    "                i = 0\n",
    "                result1 = result.find_all('div', class_='col-md col-4 hv-center phone_block pc_rank_txt') #國內回饋+其他卡片\n",
    "                for re in result1:\n",
    "                    if i == 0:\n",
    "                        print(block_name[0] +':'+ re.find('p').text)\n",
    "                        block_one2.append(re.find('p').text) #國內回饋\n",
    "                    else:\n",
    "                        print(block_name[2] +':'+ re.find('p').text)\n",
    "                        block_three2.append(re.find('p').text) #其他卡片 \n",
    "                    i+=1\n",
    "                    \n",
    "                result2 = result.find('div',class_='col-md col-4 hv-center border-left border-right phone_block pc_rank_txt') #國外回饋\n",
    "                print(block_name[1] +':'+ result2.find('p').text)\n",
    "                block_two2.append(result2.find('p').text)\n",
    "                print('\\n')\n",
    "                \n",
    "            elif j > 10: #有門檻\n",
    "                print(j)\n",
    "                i = 0\n",
    "                result1 = result.find_all('div', class_='col-md col-4 hv-center phone_block pc_rank_txt') #國內回饋+其他卡片\n",
    "                for re in result1:\n",
    "                    if i == 0:\n",
    "                        print(block_name[0] +':'+ re.find('p').text)\n",
    "                        block_one2.append(re.find('p').text) #國內回饋\n",
    "                    else:\n",
    "                        print(block_name[2] +':'+ re.find('p').text)\n",
    "                        block_three2.append(re.find('p').text) #其他卡片\n",
    "                    i+=1\n",
    "                    \n",
    "                result2 = result.find('div',class_='col-md col-4 hv-center border-left border-right phone_block pc_rank_txt') #國外回饋\n",
    "                print(block_name[1] +':'+ result2.find('p').text)\n",
    "                block_two2.append(result2.find('p').text)\n",
    "                \n",
    "            j+=1  \n",
    "            \n",
    "        ranking_card_dict1 = { #無門檻\n",
    "            '卡名':card_name1,\n",
    "            #'卡連結':card_link1,\n",
    "            block_name[0]:block_one1,\n",
    "            block_name[1]:block_two1,\n",
    "            block_name[2]:block_three1\n",
    "        }\n",
    "        ranking_card_dict2 = { #有門檻\n",
    "            '卡名':card_name2,\n",
    "            #'卡連結':card_link2,\n",
    "            block_name[0]:block_one2,\n",
    "            block_name[1]:block_two2,\n",
    "            block_name[2]:block_three2\n",
    "        }\n",
    "        \n",
    "        df1 = pd.DataFrame(ranking_card_dict1)\n",
    "        df2 = pd.DataFrame(ranking_card_dict2)\n",
    "        folder_name = 'carducsv'\n",
    "        path = \"/Users/takoyaki/Downloads/專題爬蟲\"\n",
    "        #path='/Users/takoyaki/Downloads/專題爬蟲/carducsv/'\n",
    "        folder_path = os.path.join(path, folder_name)\n",
    "        if not os.path.isdir(folder_path):\n",
    "            os.makedirs(folder_path, mode=0o777)\n",
    "        path0 = str(path+'/'+folder_name+\"/\")\n",
    "        df1.to_csv(path0+'cardu'+card_ranking_type[k]+'無門檻排行.csv', index = False)\n",
    "        df2.to_csv(path0+'cardu'+card_ranking_type[k]+'有門檻排行.csv', index = False)\n",
    "        print('\\n')\n",
    "    else:\n",
    "        results = soup.find_all('div', class_='col-md-11 wx-100-ph')\n",
    "        for result in results:\n",
    "            name = result.find('h5', class_='money_main mb-0')\n",
    "            link = result.find('a').get('href')\n",
    "            print(name.text)\n",
    "            card_name.append(name.text)\n",
    "            card_link.append('https://www.cardu.com.tw'+link[2:])\n",
    "            print('https://www.cardu.com.tw'+link[2:])\n",
    "            \n",
    "        results=soup.find_all('div', class_='row w-h-100')\n",
    "        for result in results:\n",
    "            result1 = result.find_all('div', class_='col-md hv-center phone_block col-4 py-2 pc_rank_txt') #國內回饋+其他卡片\n",
    "            i = 0\n",
    "            for re in result1:\n",
    "                if i == 0:\n",
    "                    print(block_name[0] +':'+ re.find('p').text)\n",
    "                    block_one.append(re.find('p').text) #國內回饋\n",
    "                else:\n",
    "                    print(block_name[2] +':'+ re.find('p').text)\n",
    "                    block_three.append(re.find('p').text) #其他卡片\n",
    "                i+=1\n",
    "                \n",
    "            result2 = result.find('div',class_='col-md hv-center border-left border-right phone_block col-4 py-2 pc_rank_txt') #國外回饋\n",
    "            print(block_name[1] +':'+ result2.find('p').text)\n",
    "            block_two.append(result2.find('p').text)\n",
    "            \n",
    "        ranking_card_dict = { #一般\n",
    "            '卡名':card_name,\n",
    "            #'卡連結':card_link,\n",
    "            block_name[0]:block_one,\n",
    "            block_name[1]:block_two,\n",
    "            block_name[2]:block_three\n",
    "        }\n",
    "        df = pd.DataFrame(ranking_card_dict)\n",
    "        \n",
    "        folder_name = 'carducsv'\n",
    "        path = \"/Users/takoyaki/Downloads/專題爬蟲\"  \n",
    "\n",
    "        folder_path = os.path.join(path, folder_name)\n",
    "        if not os.path.isdir(folder_path):\n",
    "            os.makedirs(folder_path, mode=0o777)\n",
    "        path0 = str(path+'/'+folder_name+\"/\")\n",
    "        #path='/Users/takoyaki/Downloads/專題爬蟲/carducsv/'\n",
    "        df.to_csv(path0+'cardu'+card_ranking_type[k]+'排行.csv', index = False)\n",
    "        print('\\n')\n",
    "    \n",
    "    if card_ranking_type[k] == '現金回饋':\n",
    "        for i in range(len(card_link1)+len(card_link2)):\n",
    "            if i<10: #無門檻\n",
    "                driver.get(card_link1[i]) #自動打開網頁（不要關）\n",
    "                print(card_name1[i])\n",
    "                name = card_name1[i]\n",
    "            else: #有門檻\n",
    "                driver.get(card_link2[i-10]) #自動打開網頁（不要關）\n",
    "                print(card_name2[i-10])\n",
    "                name = card_name2[i-10]\n",
    "            time.sleep(3) #暫停\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser') #把script變成美麗湯可讀\n",
    "            \n",
    "            #卡圖片\n",
    "            card_img = []\n",
    "            result = soup.find('img', class_='ccard_img')\n",
    "            if result !=None:\n",
    "                card_img.append(result.get('src'))\n",
    "                print(result.get('src'))\n",
    "                \n",
    "                #申請連結\n",
    "                card_apply_link = []\n",
    "                result = soup.find('a', class_='btn btn-block warning-layered btnOver')\n",
    "                if result != None:\n",
    "                    card_apply_link.append(result.get('href'))\n",
    "                    print(result.get('href'))\n",
    "                else:\n",
    "                    card_apply_link.append('無')\n",
    "                           \n",
    "                #優惠\n",
    "                summary_title = []\n",
    "                summary_text = []\n",
    "                results = soup.find_all('div', class_='col-md-6 py-1')\n",
    "                for result in results:\n",
    "                    print(result.text)\n",
    "                    summary_text.append(result.text[:-1])\n",
    "                    summary_title.append('特色')\n",
    "                           \n",
    "                #全部權益           \n",
    "                button= driver.find_element(By.ID, \"special_3-tab\") \n",
    "                button.click()\n",
    "                time.sleep(2)  \n",
    "                soup = BeautifulSoup(driver.page_source, 'html.parser') #把script變成美麗湯可讀\n",
    "                           \n",
    "                #上標題\n",
    "                title = []\n",
    "                result = soup.find('form', class_='credit_boot')\n",
    "                result1 = result.find_all('th')\n",
    "                for result in result1:\n",
    "                    print(result.text[:4])\n",
    "                    title.append(result.text[:4])\n",
    "                    \n",
    "                #內文\n",
    "                title_list = [] #標題\n",
    "                text_list = [] #內容\n",
    "                #result2 = soup.find('table')\n",
    "                #print(result2)\n",
    "                result3 = soup.find('div', id ='special_3')\n",
    "                result2 = result3.find('tbody')\n",
    "                #print(result2)\n",
    "                result2 = result2.find_all('tr')\n",
    "                for result in result2:\n",
    "                    i = 0\n",
    "                    results = result.find_all('td')\n",
    "                    for result in results:\n",
    "                        if i == 0:\n",
    "                            print(result.find('label').text)\n",
    "                            title_list.append(result.find('label').text)\n",
    "                        else:\n",
    "                            print(result.text)\n",
    "                            text_list.append(result.text)\n",
    "                        i+=1\n",
    "                keyword='、'.join(summary_text) #把大標當關鍵字\n",
    "    \n",
    "                card_dict = { \n",
    "                    #'卡圖片':card_img,\n",
    "                    #'申請連結':card_apply_link,\n",
    "                    summary_title[0]:keyword\n",
    "                }\n",
    "                \n",
    "                card_dict1={\n",
    "                    title[0]:title_list,\n",
    "                    title[1]:text_list\n",
    "                }\n",
    "                \n",
    "                df1 = pd.DataFrame(card_dict1)\n",
    "                df = pd.DataFrame(card_dict)\n",
    "                folder_name = 'carducsv'+card_ranking_type[k]\n",
    "                path = \"/Users/takoyaki/Downloads/專題爬蟲\"  \n",
    "        \n",
    "                folder_path = os.path.join(path, folder_name)\n",
    "                if not os.path.isdir(folder_path):\n",
    "                    os.makedirs(folder_path, mode=0o777)\n",
    "                path0 = str(path+'/'+folder_name+\"/\")\n",
    "                #path='/Users/takoyaki/Downloads/專題爬蟲/carducsv/'\n",
    "                df1.to_csv(path0+'cardu'+name+'權益.csv', index = False)\n",
    "                df.to_csv(path0+'cardu'+name+'.csv', index = False)\n",
    "                \n",
    "            else:\n",
    "                cards = soup.find_all('a', class_='card_name my-2')\n",
    "                for card in cards:\n",
    "                    card_img = []\n",
    "                    driver.get('https://www.cardu.com.tw'+card.get('href')[2:]) #自動打開網頁（不要關）\n",
    "                    time.sleep(3) #暫停\n",
    "                    soup = BeautifulSoup(driver.page_source, 'html.parser') #把script變成美麗湯可讀\n",
    "                    \n",
    "                    result = soup.find('img', class_='ccard_img')\n",
    "                    card_img.append(result.get('src'))\n",
    "                    print(result.get('src'))\n",
    "                    \n",
    "                    #申請連結\n",
    "                    card_apply_link = []\n",
    "                    result = soup.find('a', class_='btn btn-block warning-layered btnOver')\n",
    "                    if result != None:\n",
    "                        card_apply_link.append(result.get('href'))\n",
    "                        print(result.get('href'))\n",
    "                    else:\n",
    "                        card_apply_link.append('無')\n",
    "                               \n",
    "                    #優惠\n",
    "                    summary_title = []\n",
    "                    summary_text = []\n",
    "                    results = soup.find_all('div', class_='col-md-6 py-1')\n",
    "                    for result in results:\n",
    "                        print(result.text)\n",
    "                        summary_text.append(result.text[:-1])\n",
    "                        summary_title.append('特色')\n",
    "                               \n",
    "                    #全部權益           \n",
    "                    button= driver.find_element(By.ID, \"special_3-tab\") \n",
    "                    button.click()\n",
    "                    time.sleep(2)  \n",
    "                    soup = BeautifulSoup(driver.page_source, 'html.parser') #把script變成美麗湯可讀\n",
    "                               \n",
    "                    #上標題\n",
    "                    title = []\n",
    "                    result = soup.find('form', class_='credit_boot')\n",
    "                    result1 = result.find_all('th')\n",
    "                    for result in result1:\n",
    "                        print(result.text[:4])\n",
    "                        title.append(result.text[:4])\n",
    "                        \n",
    "                    #內文\n",
    "                    title_list = [] #標題\n",
    "                    text_list = [] #內容\n",
    "                    #result2 = soup.find('table')\n",
    "                    #print(result2)\n",
    "                    result3 = soup.find('div', id ='special_3')\n",
    "                    result2 = result3.find('tbody')\n",
    "                    #print(result2)\n",
    "                    result2 = result2.find_all('tr')\n",
    "                    for result in result2:\n",
    "                        i = 0\n",
    "                        results = result.find_all('td')\n",
    "                        for result in results:\n",
    "                            if i == 0:\n",
    "                                print(result.find('label').text)\n",
    "                                title_list.append(result.find('label').text)\n",
    "                            else:\n",
    "                                print(result.text)\n",
    "                                text_list.append(result.text)\n",
    "                            i+=1\n",
    "                    keyword='、'.join(summary_text) #把大標當關鍵字\n",
    "        \n",
    "                    card_dict = { \n",
    "                        #'卡圖片':card_img,\n",
    "                        #'申請連結':card_apply_link,\n",
    "                        summary_title[0]:keyword\n",
    "                    }\n",
    "                    \n",
    "                    card_dict1={\n",
    "                        title[0]:title_list,\n",
    "                        title[1]:text_list\n",
    "                    }\n",
    "                    \n",
    "                    df1 = pd.DataFrame(card_dict1)\n",
    "                    df = pd.DataFrame(card_dict)\n",
    "                    \n",
    "                    folder_name = 'carducsv'+card_ranking_type[k]\n",
    "                    path = \"/Users/takoyaki/Downloads/專題爬蟲\"  \n",
    "            \n",
    "                    folder_path = os.path.join(path, folder_name)\n",
    "                    if not os.path.isdir(folder_path):\n",
    "                        os.makedirs(folder_path, mode=0o777)\n",
    "                    path0 = str(path+'/'+folder_name+\"/\")\n",
    "                    \n",
    "                    #path='/Users/takoyaki/Downloads/專題爬蟲/carducsv/'\n",
    "                    df1.to_csv(path0+'cardu'+card_name[0]+'權益.csv', index = False)\n",
    "                    df.to_csv(path0+'cardu'+card_name[0]+'.csv', index = False) \n",
    "            \n",
    "    else:\n",
    "        for i in range(len(card_link)):\n",
    "            driver.get(card_link[i]) #自動打開網頁（不要關）\n",
    "            print(card_name[i])\n",
    "            time.sleep(3) #暫停\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser') #把script變成美麗湯可讀\n",
    "            \n",
    "            #卡圖片\n",
    "            card_img = []\n",
    "            result = soup.find('img', class_='ccard_img')\n",
    "            if result !=None:\n",
    "                card_img.append(result.get('src'))\n",
    "                print(result.get('src'))\n",
    "                \n",
    "                #申請連結\n",
    "                card_apply_link = []\n",
    "                result = soup.find('a', class_='btn btn-block warning-layered btnOver')\n",
    "                if result != None:\n",
    "                    card_apply_link.append(result.get('href'))\n",
    "                    print(result.get('href'))\n",
    "                else:\n",
    "                    card_apply_link.append('無')\n",
    "                           \n",
    "                #優惠\n",
    "                summary_title = []\n",
    "                summary_text = []\n",
    "                results = soup.find_all('div', class_='col-md-6 py-1')\n",
    "                for result in results:\n",
    "                    print(result.text)\n",
    "                    summary_text.append(result.text[:-1])\n",
    "                    summary_title.append('特色')\n",
    "                           \n",
    "                #全部權益           \n",
    "                button= driver.find_element(By.ID, \"special_3-tab\") \n",
    "                button.click()\n",
    "                time.sleep(2)  \n",
    "                soup = BeautifulSoup(driver.page_source, 'html.parser') #把script變成美麗湯可讀\n",
    "                           \n",
    "                #上標題\n",
    "                title = []\n",
    "                result = soup.find('form', class_='credit_boot')\n",
    "                result1 = result.find_all('th')\n",
    "                for result in result1:\n",
    "                    print(result.text[:4])\n",
    "                    title.append(result.text[:4])\n",
    "                    \n",
    "                #內文\n",
    "                title_list = [] #標題\n",
    "                text_list = [] #內容\n",
    "                #result2 = soup.find('table')\n",
    "                #print(result2)\n",
    "                result3 = soup.find('div', id ='special_3')\n",
    "                result2 = result3.find('tbody')\n",
    "                #print(result2)\n",
    "                result2 = result2.find_all('tr')\n",
    "                for result in result2:\n",
    "                    i = 0\n",
    "                    results = result.find_all('td')\n",
    "                    for result in results:\n",
    "                        if i == 0:\n",
    "                            print(result.find('label').text)\n",
    "                            title_list.append(result.find('label').text)\n",
    "                        else:\n",
    "                            print(result.text)\n",
    "                            text_list.append(result.text)\n",
    "                        i+=1\n",
    "                keyword='、'.join(summary_text) #把大標當關鍵字\n",
    "    \n",
    "                card_dict = { \n",
    "                    #'卡圖片':card_img,\n",
    "                    #'申請連結':card_apply_link,\n",
    "                    summary_title[0]:keyword\n",
    "                }\n",
    "                \n",
    "                card_dict1={\n",
    "                    title[0]:title_list,\n",
    "                    title[1]:text_list\n",
    "                }\n",
    "                \n",
    "                df1 = pd.DataFrame(card_dict1)\n",
    "                df = pd.DataFrame(card_dict)\n",
    "                folder_name = 'carducsv'+card_ranking_type[k]\n",
    "                path = \"/Users/takoyaki/Downloads/專題爬蟲\"  \n",
    "        \n",
    "                folder_path = os.path.join(path, folder_name)\n",
    "                if not os.path.isdir(folder_path):\n",
    "                    os.makedirs(folder_path, mode=0o777)\n",
    "                path0 = str(path+'/'+folder_name+\"/\")\n",
    "                #path='/Users/takoyaki/Downloads/專題爬蟲/carducsv/'\n",
    "                \n",
    "                df1.to_csv(path0+'icardu'+card_name[0]+'權益.csv', index = False)\n",
    "                df.to_csv(path0+'icardu'+card_name[0]+'.csv', index = False)\n",
    "                \n",
    "            else:\n",
    "                cards = soup.find_all('a', class_='card_name my-2')\n",
    "                for card in cards:\n",
    "                    card_img = []\n",
    "                    driver.get('https://www.cardu.com.tw'+card.get('href')[2:]) #自動打開網頁（不要關）\n",
    "                    time.sleep(3) #暫停\n",
    "                    soup = BeautifulSoup(driver.page_source, 'html.parser') #把script變成美麗湯可讀\n",
    "                    \n",
    "                    result = soup.find('img', class_='ccard_img')\n",
    "                    card_img.append(result.get('src'))\n",
    "                    print(result.get('src'))\n",
    "                    \n",
    "                    #申請連結\n",
    "                    card_apply_link = []\n",
    "                    result = soup.find('a', class_='btn btn-block warning-layered btnOver')\n",
    "                    if result != None:\n",
    "                        card_apply_link.append(result.get('href'))\n",
    "                        print(result.get('href'))\n",
    "                    else:\n",
    "                        card_apply_link.append('無')\n",
    "                               \n",
    "                    #優惠\n",
    "                    summary_title = []\n",
    "                    summary_text = []\n",
    "                    results = soup.find_all('div', class_='col-md-6 py-1')\n",
    "                    for result in results:\n",
    "                        print(result.text)\n",
    "                        summary_text.append(result.text[:-1])\n",
    "                        summary_title.append('特色')\n",
    "                               \n",
    "                    #全部權益           \n",
    "                    button= driver.find_element(By.ID, \"special_3-tab\") \n",
    "                    button.click()\n",
    "                    time.sleep(2)  \n",
    "                    soup = BeautifulSoup(driver.page_source, 'html.parser') #把script變成美麗湯可讀\n",
    "                               \n",
    "                    #上標題\n",
    "                    title = []\n",
    "                    result = soup.find('form', class_='credit_boot')\n",
    "                    result1 = result.find_all('th')\n",
    "                    for result in result1:\n",
    "                        print(result.text[:4])\n",
    "                        title.append(result.text[:4])\n",
    "                        \n",
    "                    #內文\n",
    "                    title_list = [] #標題\n",
    "                    text_list = [] #內容\n",
    "                    #result2 = soup.find('table')\n",
    "                    #print(result2)\n",
    "                    result3 = soup.find('div', id ='special_3')\n",
    "                    result2 = result3.find('tbody')\n",
    "                    #print(result2)\n",
    "                    result2 = result2.find_all('tr')\n",
    "                    for result in result2:\n",
    "                        i = 0\n",
    "                        results = result.find_all('td')\n",
    "                        for result in results:\n",
    "                            if i == 0:\n",
    "                                print(result.find('label').text)\n",
    "                                title_list.append(result.find('label').text)\n",
    "                            else:\n",
    "                                print(result.text)\n",
    "                                text_list.append(result.text)\n",
    "                            i+=1\n",
    "                    keyword='、'.join(summary_text) #把大標當關鍵字\n",
    "        \n",
    "                    card_dict = { \n",
    "                        #'卡圖片':card_img,\n",
    "                        #'申請連結':card_apply_link,\n",
    "                        summary_title[0]:keyword\n",
    "                    }\n",
    "                    \n",
    "                    card_dict1={\n",
    "                        title[0]:title_list,\n",
    "                        title[1]:text_list\n",
    "                    }\n",
    "                    \n",
    "                    df1 = pd.DataFrame(card_dict1)\n",
    "                    df = pd.DataFrame(card_dict)\n",
    "                    folder_name = 'carducsv'+card_ranking_type[k]\n",
    "                    path = \"/Users/takoyaki/Downloads/專題爬蟲\"  \n",
    "            \n",
    "                    folder_path = os.path.join(path, folder_name)\n",
    "                    if not os.path.isdir(folder_path):\n",
    "                        os.makedirs(folder_path, mode=0o777)\n",
    "                    path0 = str(path+'/'+folder_name+\"/\")\n",
    "                    #path='/Users/takoyaki/Downloads/專題爬蟲/carducsv/'\n",
    "                    \n",
    "                    df1.to_csv(path0+'icardu'+card_name[0]+'權益.csv', index = False)\n",
    "                    df.to_csv(path0+'icardu'+card_name[0]+'.csv', index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
